{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:997)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Movie Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/zg23p5bd3bnc86d75_pkn99m0000gn/T/ipykernel_98629/4212106273.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta = pd.read_csv(path+movie_meta_file)\n"
     ]
    }
   ],
   "source": [
    "path = \"../data\"\n",
    "movie_meta_file = \"/movies_metadata.csv\"\n",
    "df_meta = pd.read_csv(path+movie_meta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_meta = df_meta.drop([19730, 29503, 35587])\n",
    "df_meta = df_meta.set_index(df_meta['id'].str.strip().replace(',','').astype(int))\n",
    "\n",
    "\n",
    "# Extract important features\n",
    "\n",
    "meta_features = ['genres', 'imdb_id', 'original_language', 'revenue', 'release_date', 'spoken_languages', 'title', 'vote_average', 'vote_count', 'overview']\n",
    "meta = df_meta[meta_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "      <td>[{'credit_id': '52fe4284c3a36847f8024f49', 'de...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "      <td>[{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...</td>\n",
       "      <td>8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "      <td>[{'credit_id': '52fe466a9251416c75077a89', 'de...</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "      <td>[{'credit_id': '52fe44779251416c91011acb', 'de...</td>\n",
       "      <td>31357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "      <td>[{'credit_id': '52fe44959251416c75039ed7', 'de...</td>\n",
       "      <td>11862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45471</th>\n",
       "      <td>[{'cast_id': 0, 'character': '', 'credit_id': ...</td>\n",
       "      <td>[{'credit_id': '5894a97d925141426c00818c', 'de...</td>\n",
       "      <td>439050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45472</th>\n",
       "      <td>[{'cast_id': 1002, 'character': 'Sister Angela...</td>\n",
       "      <td>[{'credit_id': '52fe4af1c3a36847f81e9b15', 'de...</td>\n",
       "      <td>111109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45473</th>\n",
       "      <td>[{'cast_id': 6, 'character': 'Emily Shaw', 'cr...</td>\n",
       "      <td>[{'credit_id': '52fe4776c3a368484e0c8387', 'de...</td>\n",
       "      <td>67758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45474</th>\n",
       "      <td>[{'cast_id': 2, 'character': '', 'credit_id': ...</td>\n",
       "      <td>[{'credit_id': '533bccebc3a36844cf0011a7', 'de...</td>\n",
       "      <td>227506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45475</th>\n",
       "      <td>[]</td>\n",
       "      <td>[{'credit_id': '593e676c92514105b702e68e', 'de...</td>\n",
       "      <td>461257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45476 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    cast  \\\n",
       "0      [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
       "1      [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
       "2      [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
       "3      [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
       "4      [{'cast_id': 1, 'character': 'George Banks', '...   \n",
       "...                                                  ...   \n",
       "45471  [{'cast_id': 0, 'character': '', 'credit_id': ...   \n",
       "45472  [{'cast_id': 1002, 'character': 'Sister Angela...   \n",
       "45473  [{'cast_id': 6, 'character': 'Emily Shaw', 'cr...   \n",
       "45474  [{'cast_id': 2, 'character': '', 'credit_id': ...   \n",
       "45475                                                 []   \n",
       "\n",
       "                                                    crew      id  \n",
       "0      [{'credit_id': '52fe4284c3a36847f8024f49', 'de...     862  \n",
       "1      [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...    8844  \n",
       "2      [{'credit_id': '52fe466a9251416c75077a89', 'de...   15602  \n",
       "3      [{'credit_id': '52fe44779251416c91011acb', 'de...   31357  \n",
       "4      [{'credit_id': '52fe44959251416c75039ed7', 'de...   11862  \n",
       "...                                                  ...     ...  \n",
       "45471  [{'credit_id': '5894a97d925141426c00818c', 'de...  439050  \n",
       "45472  [{'credit_id': '52fe4af1c3a36847f81e9b15', 'de...  111109  \n",
       "45473  [{'credit_id': '52fe4776c3a368484e0c8387', 'de...   67758  \n",
       "45474  [{'credit_id': '533bccebc3a36844cf0011a7', 'de...  227506  \n",
       "45475  [{'credit_id': '593e676c92514105b702e68e', 'de...  461257  \n",
       "\n",
       "[45476 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# credits \n",
    "\n",
    "credits = pd.read_csv(path+ \"/credits.csv\")\n",
    "\n",
    "credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create col for directors\n",
    "credits['Director'] = credits['crew'].apply(lambda x:[dct['name'] for dct in ast.literal_eval(x) if dct['job'] == 'Director'])\n",
    "\n",
    "df_credits = credits.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords \n",
    "\n",
    "df_keywords = pd.read_csv(path + \"/keywords.csv\")\n",
    "\n",
    "df_keywords = df_keywords.set_index('id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging datasets\n",
    "df_key_credit = df_keywords.merge(df_credits, left_index=True, right_on='id')\n",
    "df = df_key_credit.merge(meta, left_index=True, right_on='id')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)])\n",
    "\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "\n",
    "\n",
    "df['keywords'] = df['keywords'].apply(lambda x: [i['name'] for i in eval(x)])\n",
    "df['keywords'] = df['keywords'].apply(lambda x: ' '.join([i.replace(\" \", \"\") for i in x]))\n",
    "\n",
    "# extract the overview\n",
    "df['overview'] = df['overview'].fillna('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting final dataframe to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_movie.csv\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP - Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/andresrivera/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andresrivera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/andresrivera/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_overview(text):\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "     # Convert to lowercase and remove non-alphanumeric characters\n",
    "    words = [word.lower() for word in tokens if word.isalnum()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    \n",
    "    return lemmatized_words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[\"overview\"].apply(preprocess_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text data\n",
    "def extract_keywords(row):\n",
    "    keyword_list = ast.literal_eval(row['keywords'])\n",
    "    keywords = [kw['name'] for kw in keyword_list]\n",
    "    directors = row['directors']\n",
    "    #overview_keywords = preprocess_overview(row['overview'])\n",
    "    genres = row['genres'].lower().split(' ')\n",
    "\n",
    "    return genres + keywords + directors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_movies = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Genres\n",
    "df_movies['genres'] = df_movies['genres'].apply(lambda x: ' '.join([i.replace(\" \", \"\") for i in x]))\n",
    "df_movies['keywords'] = df['keywords']\n",
    "df_movies['directors'] = df['Director']\n",
    "\n",
    "# Text analysis\n",
    "\n",
    "df_movies['combined_keywords'] = df_movies.apply(extract_keywords, axis=1)\n",
    "\n",
    "df_movies['title'] = df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows with no genres\n",
    "\n",
    "mask = df_movies['genres'].str.strip() != \"\"\n",
    "\n",
    "df_movies = df_movies[mask]\n",
    "\n",
    "df_movies.genres.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/zg23p5bd3bnc86d75_pkn99m0000gn/T/ipykernel_84307/3582924666.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_movies['combined_keywords_str'] = df_movies['combined_keywords'].apply(join_keywords)\n"
     ]
    }
   ],
   "source": [
    "def join_keywords(keywords_list):\n",
    "    return ' '.join(keywords_list)\n",
    "\n",
    "df_movies['combined_keywords_str'] = df_movies['combined_keywords'].apply(join_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_movies['combined_keywords_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "191185           My Sweet Orange Tree\n",
      "383146                        Curumim\n",
      "40823              The Man Who Copied\n",
      "64397     Basic Sanitation, the Movie\n",
      "29275                           Anita\n",
      "72560              Federal Bank Heist\n",
      "81022                          Widows\n",
      "78705                    Live-In Maid\n",
      "113329           Artificial Paradises\n",
      "222772                   Lion's Heart\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommended_movies = recommend_movies(\"Inception\", 10)\n",
    "print(recommended_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(title, num_recommendations=10):\n",
    "    # Get the index of the movie with the given title\n",
    "    movie_index = df_movies[df_movies['title'] == title].index[0]\n",
    "\n",
    "    # Get the list of cosine similarity scores for the given movie\n",
    "    similarity_scores = list(enumerate(cosine_sim[movie_index]))\n",
    "\n",
    "    # Sort the scores in descending order\n",
    "    similarity_scores_sorted = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the most similar movies (excluding the input movie itself)\n",
    "    similar_movie_indices = [score[0] for score in similarity_scores_sorted[1:num_recommendations + 1]]\n",
    "\n",
    "    # Return the titles of the most similar movies\n",
    "    return df_movies['title'].iloc[similar_movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45432, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>jealousy toy boy friendship friends rivalry boynextdoor newtoy toycomestolifeTomHanks TimAllen DonRickles JimVarney WallaceShawn JohnRatzenberger AnniePotts JohnMorris ErikvonDetten LaurieMetcalf R.LeeErmey SarahFreeman PennJillette Animation Comedy Family 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8844</th>\n",
       "      <td>1</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>boardgame disappearance basedonchildren'sbook newhome recluse giantinsectRobinWilliams JonathanHyde KirstenDunst BradleyPierce BonnieHunt BebeNeuwirth DavidAlanGrier PatriciaClarkson AdamHann-Byrd LauraBellBundy JamesHandy GillianBarber BrandonObray CyrusThiedeke GaryJosephThorup LeonardZola LloydBerry MalcolmStewart AnnabelKershaw DarrylHenriques RobynDriscoll PeterBryant SarahGilson FloricaVlad JuneLion BrendaLockmuller Adventure Fantasy Family 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15602</th>\n",
       "      <td>2</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>fishing bestfriend duringcreditsstinger oldmenWalterMatthau JackLemmon Ann-Margret SophiaLoren DarylHannah BurgessMeredith KevinPollak Romance Comedy 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31357</th>\n",
       "      <td>3</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>basedonnovel interracialrelationship singlemother divorce chickflickWhitneyHouston AngelaBassett LorettaDevine LelaRochon GregoryHines DennisHaysbert MichaelBeach MykeltiWilliamson LamontJohnson WesleySnipes Comedy Drama Romance 1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11862</th>\n",
       "      <td>4</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>baby midlifecrisis confidence aging daughter motherdaughterrelationship pregnancy contraception gynecologistSteveMartin DianeKeaton MartinShort KimberlyWilliams-Paisley GeorgeNewbern KieranCulkin BDWong PeterMichaelGoetz KateMcGregor-Stewart JaneAdams EugeneLevy LoriAlan Comedy 1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       new_id                        title                                                                                                                                                                                                                                                                                                                                                                                                                                                                     tags\n",
       "id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "862         0                    Toy Story                                                                                                                                                                                                    jealousy toy boy friendship friends rivalry boynextdoor newtoy toycomestolifeTomHanks TimAllen DonRickles JimVarney WallaceShawn JohnRatzenberger AnniePotts JohnMorris ErikvonDetten LaurieMetcalf R.LeeErmey SarahFreeman PennJillette Animation Comedy Family 1995\n",
       "8844        1                      Jumanji  boardgame disappearance basedonchildren'sbook newhome recluse giantinsectRobinWilliams JonathanHyde KirstenDunst BradleyPierce BonnieHunt BebeNeuwirth DavidAlanGrier PatriciaClarkson AdamHann-Byrd LauraBellBundy JamesHandy GillianBarber BrandonObray CyrusThiedeke GaryJosephThorup LeonardZola LloydBerry MalcolmStewart AnnabelKershaw DarrylHenriques RobynDriscoll PeterBryant SarahGilson FloricaVlad JuneLion BrendaLockmuller Adventure Fantasy Family 1995\n",
       "15602       2             Grumpier Old Men                                                                                                                                                                                                                                                                                                               fishing bestfriend duringcreditsstinger oldmenWalterMatthau JackLemmon Ann-Margret SophiaLoren DarylHannah BurgessMeredith KevinPollak Romance Comedy 1995\n",
       "31357       3            Waiting to Exhale                                                                                                                                                                                                                                basedonnovel interracialrelationship singlemother divorce chickflickWhitneyHouston AngelaBassett LorettaDevine LelaRochon GregoryHines DennisHaysbert MichaelBeach MykeltiWilliamson LamontJohnson WesleySnipes Comedy Drama Romance 1995\n",
       "11862       4  Father of the Bride Part II                                                                                                                                                                              baby midlifecrisis confidence aging daughter motherdaughterrelationship pregnancy contraception gynecologistSteveMartin DianeKeaton MartinShort KimberlyWilliams-Paisley GeorgeNewbern KieranCulkin BDWong PeterMichaelGoetz KateMcGregor-Stewart JaneAdams EugeneLevy LoriAlan Comedy 1995"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty DataFrame\n",
    "df_movies = pd.DataFrame()\n",
    "\n",
    "# extract the keywords\n",
    "df_movies['keywords'] = df['keywords'].apply(lambda x: [i['name'] for i in eval(x)])\n",
    "df_movies['keywords'] = df_movies['keywords'].apply(lambda x: ' '.join([i.replace(\" \", \"\") for i in x]))\n",
    "\n",
    "# extract the overview\n",
    "df_movies['overview'] = df['overview'].fillna('')\n",
    "\n",
    "# extract the release year \n",
    "df_movies['release_date'] = pd.to_datetime(df['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "\n",
    "# extract the actors\n",
    "df_movies['cast'] = df['cast'].apply(lambda x: [i['name'] for i in eval(x)])\n",
    "df_movies['cast'] = df_movies['cast'].apply(lambda x: ' '.join([i.replace(\" \", \"\") for i in x]))\n",
    "\n",
    "# extract genres\n",
    "df_movies['genres'] = df['genres'].apply(lambda x: [i['name'] for i in eval(x)])\n",
    "df_movies['genres'] = df_movies['genres'].apply(lambda x: ' '.join([i.replace(\" \", \"\") for i in x]))\n",
    "\n",
    "# add the title\n",
    "df_movies['title'] = df['title']\n",
    "\n",
    "# merge fields into a tag field\n",
    "df_movies['tags'] = df_movies['keywords'] + df_movies['cast']+' '+df_movies['genres']+' '+df_movies['release_date']\n",
    "\n",
    "# drop records with empty tags and dublicates\n",
    "df_movies.drop(df_movies[df_movies['tags']==''].index, inplace=True)\n",
    "df_movies.drop_duplicates(inplace=True)\n",
    "\n",
    "# add a fresh index to the dataframe, which we will later use when refering to items in a vector matrix\n",
    "df_movies['new_id'] = range(0, len(df_movies))\n",
    "\n",
    "# Reduce the data to relevant columns\n",
    "df_movies = df_movies[['new_id', 'title', 'tags']]\n",
    "\n",
    "# display the data\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "print(df_movies.shape)\n",
    "df_movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2     3     4     5     6     7     8     9     ...  4990  4991  4992  4993  4994  4995  4996  4997  4998  4999\n",
      "862      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "8844     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "15602    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "31357    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "11862    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
      "439050   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "111109   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "67758    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "227506   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "461257   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
      "\n",
      "[45432 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "# set a custom stop list from nltk\n",
    "stop = list(stopwords.words('english'))\n",
    "\n",
    "# create the tfid vectorizer, alternatively you can also use countVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000, analyzer='word', stop_words=stop)\n",
    "vectorized_data = tfidf.fit_transform(df_movies['tags'])\n",
    "count_matrix = pd.DataFrame(vectorized_data.toarray(), index=df_movies['tags'].index.tolist())\n",
    "print(count_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# compute the cosine similarity matrixS\n",
    "similarity = cosine_similarity(reduced_data)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
